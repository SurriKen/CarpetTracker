import osimport randomimport reimport shutilfrom dataclasses import dataclassimport cv2import numpy as npimport pandas as pdimport skvideo.ioimport torchimport torchvisionfrom PIL import Imagefrom moviepy.video.io.VideoFileClip import VideoFileClipfrom torchvision.utils import draw_bounding_boxesfrom torchvision.io import read_imagefrom parameters import ROOT_DIRfrom utils import save_data, get_colors, load_txt, get_name_from_link, save_txt@dataclassclass VideoClass:    def __init__(self):        self.x_train = []        self.y_train = []        self.x_val = []        self.y_val = []        self.x_test = []        self.y_test = []        self.dataset = {}        self.classes = []        self.params = {}class DatasetProcessing:    def __init__(self):        pass    @staticmethod    def cut_video(video_path: str, save_path: str = 'datasets', from_time=0, to_time=1000) -> str:        """        Cut video in given time range.        Args:            video_path: path to video file            save_path: path to save folder            from_time: time to start cut in seconds            to_time: time to finish cut in seconds        Returns: path to saved video file        """        try:            os.mkdir(save_path)        except:            pass        video_capture = cv2.VideoCapture()        video_capture.open(video_path)        fps = video_capture.get(cv2.CAP_PROP_FPS)  # OpenCV v2.x used "CV_CAP_PROP_FPS"        frame_count = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))        duration = int(frame_count / fps)        saved_video_path = f"{save_path}/{video_path.split('/')[-1]}"        if to_time and to_time < duration:            clip = VideoFileClip(video_path).subclip(from_time, to_time)            clip.write_videofile(saved_video_path)        elif from_time:            clip = VideoFileClip(video_path).subclip(from_time, duration)            clip.write_videofile(saved_video_path)        else:            shutil.copy2(video_path, saved_video_path)        print("Video was cut and save")        return saved_video_path    @staticmethod    def synchronize_video(video_path: str, save_path: str = 'datasets', from_frame=None, to_frame=None) -> None:        video_capture = cv2.VideoCapture()        video_capture.open(video_path)        fps = video_capture.get(cv2.CAP_PROP_FPS)  # OpenCV v2.x used "CV_CAP_PROP_FPS"        frame_count = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))        print(fps)        vc = cv2.VideoCapture()        vc.open(video_path)        frames = int(vc.get(cv2.CAP_PROP_FRAME_COUNT))        size = None        for i in range(frames):            ret, frame = video_capture.read()            size = (frame.shape[1], frame.shape[0])            break        out = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*'DIVX'), fps, size)        for i in range(frame_count):            if (i + 1) % 500 == 0:                print(f"{i + 1} frames are ready")            ret, frame = video_capture.read()            if from_frame and i >= from_frame:                out.write(frame)            if to_frame and i >= to_frame:                break        out.release()        cv2.destroyAllWindows()    @staticmethod    def video_class_dataset(video_links: list, save_folder: str, separate: bool = False) -> None:        try:            os.mkdir(save_folder)        except:            shutil.rmtree(save_folder)            os.mkdir(save_folder)        count = 0        for i, vid in enumerate(video_links):            csv = vid[2]            obj = 0            data = pd.read_csv(csv)            try:                carpet_size = data['Размер']            except:                carpet_size = data['размер']            start_frame = data['Кадр начала']            end_frame = data['Кадр конца']            cls = carpet_size.unique()            for cl in cls:                cl = cl.replace('*', 'x')                if not os.path.isdir(os.path.join(save_folder, cl)):                    os.mkdir(os.path.join(save_folder, cl))                    if separate:                        os.mkdir(os.path.join(save_folder, cl, 'camera_1'))                        os.mkdir(os.path.join(save_folder, cl, 'camera_2'))            cam_1, cam_2 = vid[0], vid[1]            print(f"\n{csv}\n")            vc1 = cv2.VideoCapture()            vc1.open(cam_1)            w1 = int(vc1.get(cv2.CAP_PROP_FRAME_WIDTH))            h1 = int(vc1.get(cv2.CAP_PROP_FRAME_HEIGHT))            frames1 = int(vc1.get(cv2.CAP_PROP_FRAME_COUNT))            vc2 = cv2.VideoCapture()            vc2.open(cam_2)            frames2 = int(vc2.get(cv2.CAP_PROP_FRAME_COUNT))            w2 = int(vc2.get(cv2.CAP_PROP_FRAME_WIDTH))            h2 = int(vc2.get(cv2.CAP_PROP_FRAME_HEIGHT))            w = min([w1, w2])            h = min([h1, h2])            for j in range(min([frames1, frames2])):                _, frame1 = vc1.read()                _, frame2 = vc2.read()                if j == start_frame[obj]:                    cs = carpet_size[obj].replace('*', 'x')                    if separate:                        out1 = cv2.VideoWriter(                            os.path.join(save_folder, cs, 'camera_1', f"{count}.mp4"), cv2.VideoWriter_fourcc(*'mp4v'),                            25, (w1, h1)                        )                        out2 = cv2.VideoWriter(                            os.path.join(save_folder, cs, 'camera_2', f"{count}.mp4"), cv2.VideoWriter_fourcc(*'mp4v'),                            25, (w2, h2)                        )                    else:                        out1 = cv2.VideoWriter(                            os.path.join(save_folder, cs, f"{count}.mp4"), cv2.VideoWriter_fourcc(*'mp4v'), 25,                            (w, h * 2)                        )                if start_frame[obj] <= j <= end_frame[obj]:                    if separate:                        out1.write(frame1)                        out2.write(frame2)                    else:                        size1 = (frame1.shape[1], frame1.shape[0])                        if size1 != (w, h):                            frame1 = cv2.resize(frame1, (w, h))                        size2 = (frame2.shape[1], frame2.shape[0])                        if size2 != (w, h):                            frame2 = cv2.resize(frame2, (w, h))                        frame = np.concatenate((frame1, frame2), axis=0)                        out1.write(frame)                if j == end_frame[obj]:                    if separate:                        out1.release()                        out2.release()                    else:                        out1.release()                    obj += 1                    count += 1                if obj == len(carpet_size):                    break    @staticmethod    def change_fps(video_path: str, save_path: str, set_fps=25) -> None:        video_capture = cv2.VideoCapture()        video_capture.open(video_path)        fps = video_capture.get(cv2.CAP_PROP_FPS)  # OpenCV v2.x used "CV_CAP_PROP_FPS"        if fps == 25:            print(f"Video {video_path} already has fps = 25")        else:            clip = VideoFileClip(video_path)            clip.write_videofile(save_path, fps=set_fps)    @staticmethod    def video2frames(video_path: str, save_path: str = 'datasets', from_time=0, to_time=1000, size=(),                     step=1) -> None:        video_name = get_name_from_link(video_path)        print(video_name)        video_capture = cv2.VideoCapture()        video_capture.open(video_path)        fps = video_capture.get(cv2.CAP_PROP_FPS)  # OpenCV v2.x used "CV_CAP_PROP_FPS"        frame_count = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))        print(f"fps = {fps}, frame_count = {frame_count}")        duration = int(frame_count / fps)        if to_time:            if to_time > int(duration):                to_time = int(duration)            to_path = f"{save_path}/{video_name}_{from_time}s-{to_time}s"        elif from_time:            to_path = f"{save_path}/{video_name}_{from_time}s-{duration}s"        else:            to_path = f"{save_path}/{video_name}_{from_time}s-{duration}s"        if not os.path.isdir(to_path):            os.mkdir(to_path)        # try:        #     os.mkdir(to_path)        # except:        #     shutil.rmtree(to_path, ignore_errors=True)        #     os.mkdir(to_path)        # if not os.path.isdir(f"{to_path}/frames"):        #     os.mkdir(f"{to_path}/frames")        # os.mkdir(f"{to_path}/xml_labels")        video_capture = cv2.VideoCapture()        video_capture.open(video_path)        fps = video_capture.get(cv2.CAP_PROP_FPS)        frames = video_capture.get(cv2.CAP_PROP_FRAME_COUNT)        start = int(from_time * fps)        finish = int(to_time * fps)        print(f"Getting frames ({int(frames)} in total)...")        # size = ()        r = list(range(0, finish, step))        for i in range(0, finish):            ret, frame = video_capture.read()            if i >= start:                if (i + 1) % 200 == 0:                    print(f"{i + 1} frames are ready")                if not size:                    size = (frame.shape[1], frame.shape[0])                if i in r:                    frame = cv2.resize(frame, size)                    cv2.imwrite(f"{to_path}/{video_name}_%05d.png" % i, frame)        # video_data = {        #     "fps": int(fps), "frames": int(frames), 'size': size        # }        print(f"frames were got: fps - {int(fps)}, total frames - {int(frames)}, frame size - {size}")        # save_data(video_data, to_path, 'data')    @staticmethod    def put_box_on_image(images: str, labels: str, save_path: str) -> None:        try:            os.mkdir(save_path)        except:            shutil.rmtree(save_path)            os.mkdir(save_path)        lbl = ['carpet']        color_list = get_colors(lbl)        img_names = []        empty_box, fill_box = 0, 0        with os.scandir(images) as folder:            for f in folder:                img_names.append(f.name[:-4])        for name in img_names:            img_path = f'{images}/{name}.jpg'            box_path = f'{labels}/{name}.txt'            img = Image.open(img_path)            with open(box_path, 'r') as handle:                box_info = handle.readlines()                if box_info:                    fill_box += 1                    box_info = [re.sub(f'\n', ' ', b) for b in box_info]                else:                    empty_box += 1            coord = []            if box_info:                for box in box_info:                    if box:                        box = box.split(" ")                        coord.append([                            int((float(box[1]) - float(box[3]) / 2) * img.size[0]),                            int((float(box[2]) - float(box[4]) / 2) * img.size[1]),                            int((float(box[1]) + float(box[3]) / 2) * img.size[0]),                            int((float(box[2]) + float(box[4]) / 2) * img.size[1]),                        ])                bbox = torch.tensor(coord, dtype=torch.int)                image = read_image(img_path)                lbl2 = lbl * len(coord)                color_list2 = color_list * len(coord)                image_true = draw_bounding_boxes(image, bbox, width=3, labels=lbl2, colors=color_list2, fill=True)                image = torchvision.transforms.ToPILImage()(image_true)                image.save(f'{save_path}/{name}.png')            else:                image = read_image(img_path)                image = torchvision.transforms.ToPILImage()(image)                image.save(f'{save_path}/{name}.png')            print('fill_box=', fill_box, 'empty_box=', empty_box)    @staticmethod    def form_dataset_for_train(data: list, split: float, save_path: str, condition=None) -> None:        """        :param data: list of lists of 2 str and 1 float [[image_folder, corresponding_labels_folder, 0.5], ...]        :param split: float between 0 and 1        :param save_path: str        :param condition: dict        """        if condition is None:            condition = {}        try:            os.mkdir(save_path)            os.mkdir(f"{save_path}/train")            os.mkdir(f"{save_path}/train/images")            os.mkdir(f"{save_path}/train/labels")            os.mkdir(f"{save_path}/val")            os.mkdir(f"{save_path}/val/images")            os.mkdir(f"{save_path}/val/labels")        except:            shutil.rmtree(save_path)            os.mkdir(save_path)            os.mkdir(f"{save_path}/train")            os.mkdir(f"{save_path}/train/images")            os.mkdir(f"{save_path}/train/labels")            os.mkdir(f"{save_path}/val")            os.mkdir(f"{save_path}/val/images")            os.mkdir(f"{save_path}/val/labels")        count = 0        for folders in data:            img_list = []            print(f"Data: {folders}")            with os.scandir(folders[0]) as fold:                for f in fold:                    if f.name[-3:] in ['png', 'jpg']:                        if condition.get('orig_shape'):                            img = Image.open(f"{folders[0]}/{f.name}")                            if img.size == condition.get('orig_shape'):                                img_list.append(f.name)                        else:                            img_list.append(f.name)            with_boxes, no_boxes = [], []            with os.scandir(folders[1]) as fold:                for f in fold:                    if f.name[-3:] in ['txt'] and \                            (f"{f.name.split('.')[0]}.png" in img_list or f"{f.name.split('.')[0]}.jpg" in img_list):                        # lbl_list.append(f.name)                        if load_txt(os.path.join(folders[1], f.name)):                            with_boxes.append(f.name)                        else:                            no_boxes.append(f.name)            random.shuffle(no_boxes)            no_boxes = no_boxes[:len(with_boxes)] if len(no_boxes) > len(with_boxes) else no_boxes            with_boxes.extend(no_boxes)            random.shuffle(with_boxes)            with_boxes = with_boxes[:int(len(with_boxes) * folders[2])] if folders[2] < 1 else with_boxes            if len(with_boxes) and len(img_list):                print("Labels", len(with_boxes), len(no_boxes), with_boxes[0])                images = []                for label in with_boxes:                    if f"{label.split('.')[0]}.png" in img_list:                        images.append((f"{label.split('.')[0]}.png", label))                    if f"{label.split('.')[0]}.jpg" in img_list:                        images.append((f"{label.split('.')[0]}.jpg", label))                print("Image", len(images), images[0])                random.shuffle(images)                delimiter = int(len(images) * split)                for i, img in enumerate(images):                    if i <= delimiter:                        shutil.copy2(f"{folders[0]}/{img[0]}", f"{save_path}/train/images/{count}.jpg")                        shutil.copy2(f"{folders[1]}/{img[1]}", f"{save_path}/train/labels/{count}.txt")                    else:                        shutil.copy2(f"{folders[0]}/{img[0]}", f"{save_path}/val/images/{count}.jpg")                        shutil.copy2(f"{folders[1]}/{img[1]}", f"{save_path}/val/labels/{count}.txt")                    count += 1    @staticmethod    def video_to_array(video_path: str) -> np.ndarray:        """        Transform video to numpy array        """        return skvideo.io.vread(video_path)    @staticmethod    def ohe_from_list(data: list[int], num: int) -> np.ndarray:        """Transform list of labels to one hot encoding array"""        targets = np.array([data]).reshape(-1)        return np.eye(num)[targets]if __name__ == '__main__':    img_path = os.path.join('/media/deny/Новый том/AI/CarpetTracker', 'datasets/От разметчиков/batch_09/img')    lbl_path = os.path.join('/media/deny/Новый том/AI/CarpetTracker', 'datasets/От разметчиков/batch_09/boxes')    img_content = os.listdir(img_path)    lbl_content = os.listdir(lbl_path)    txt = ""    total, empty = 0, 0    for link in img_content:        total += 1        name = link.split('.')[0]        if f"{name}.txt" not in lbl_content:            empty += 1            save_txt(txt=txt, txt_path=os.path.join(ROOT_DIR, lbl_path, f"{name}.txt"))    print('total=', total, 'empty=', empty)    pass